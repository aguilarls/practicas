{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84b70532-71e5-48c5-bf7e-e02b937c69a1",
   "metadata": {},
   "source": [
    "# Instrucciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022fe705-4709-4029-afa4-1106781654eb",
   "metadata": {},
   "source": [
    "En este Notebook va a implementar los conceptos aprendidos en clase. Para ello implementara un __autoencoder__. Asimismo usara las librerias `UMAP` y `scikit-learn`. Antes de comenzar, proceda a instalar las librerias necesarias con lo siguientes comandos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2761b4b5-57e9-4f32-93ab-ac3048121e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b493ca1b-4823-4802-a480-a6294c9d172f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install umap-learn[plot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb260a28-c7f5-48c8-846b-aa10000377fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1c0f9c5-a84d-4d3e-a741-e0370f1db8d7",
   "metadata": {},
   "source": [
    "Ahora proceda a descargar los datos y funciones adicionales con la siguiente linea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1dce56-65ab-4232-8f80-2da6508cbdc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -OL https://raw.githubusercontent.com/aguilarls/practicas/main/Algebra-computarizada/files.tar.xz && tar -xf ./files.tar.xz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca30e57-8e3e-417b-ba6d-e23a821a686d",
   "metadata": {},
   "source": [
    "# 1. Aplicaciones de algebra lineal en datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f6e0bb-a0f8-43d9-ab7d-8da7d576706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a72ed9-3c24-426c-8bd8-5dcad9c18e09",
   "metadata": {},
   "source": [
    "## 2. Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56079651-6f5b-4cc0-9b53-a56a9ac2b20e",
   "metadata": {},
   "source": [
    "Para esta aplicacion, vamos a usar un subset del dataset __MNIST__. Este dataset contiene imagenes de numeros del 0 al 9 escritos a mano. Las dimensiones de las imagenes son `28 * 28` pixeles. Usaremos la siguiente funcion para cargar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d04784a-0525-4b27-9432-bad22c0b1aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, targets = get_data('dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c326625-a356-4fe0-b0dd-c5898dc16f0a",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "1. Pregunta: Cuantos datos y caracteristicas contiene el data set?.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d95536-639b-4bca-a9a4-a5ffb62237f6",
   "metadata": {},
   "source": [
    "Ahora vamos a visualizar una parte del dataset. Para ello ejecutaremos el siguiente comando:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9552fc-f711-4fb1-8031-58fdadb46835",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e0fcd8-a75e-4ee5-9dfb-b43067b2aa03",
   "metadata": {},
   "source": [
    "## 3. Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e57086-7928-4d31-abc5-0a6f64b2bc6d",
   "metadata": {},
   "source": [
    "En esta seccion vamos a realizar el preprocesamiento de los datos. Esta es una etapa fundamental que se debe de realizar antes de poder aplicar redes neuronales. Existen diversas opciones de preprocesamiento, se debe de elegir la que mas se adecua a los datos y modelo a usar. En este caso vamos a __escalar__ (transformar) los datos aplicando la siguiente ecuacion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3771042-ad59-4f84-a47c-7257bf6fad63",
   "metadata": {},
   "source": [
    "$$\n",
    "\\large X_{s} = X_{\\sigma} * (a - b) + b\n",
    "$$\n",
    "Donde:\n",
    "* $ \\large X_{\\sigma} = \\frac{X - X_{min}}{X_{max} - X_{min}}$\n",
    "* $a$ representa el limite inferior.\n",
    "* $b$ representa el limite mayor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c374800-3ea0-494b-a0ef-4c2bfb5c85da",
   "metadata": {},
   "source": [
    "Ya que vamos a trabajar con __redes neuronales__, vamos a usar `0` y `1` para los intervalos $(a,b)$, esto ayudara a la convergencia de nuestra red. Asimismo, ya que estamos trabajando con imagenes, los valores `0` y `1` normalizaran la intensidad de los pixeles. Para la implementacion de la ecuacion vamos a usar la `clase` [MinMaxScaler](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn-preprocessing-minmaxscaler) from `scikit-learn`, donde especificaremos $(a, b)$ con el argumento `feature_range=(0, 1)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0923eac-a94e-478a-8876-bbf2855cf31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5602e2d0-59ef-4ddc-81e4-c877bdbe71a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ef3f48-7a6e-406d-ac4e-ab62181cd013",
   "metadata": {},
   "source": [
    "Ahora procederemos a preprocesar los datos usando el comando `fit_transform`. Este comando se divide en dos acciones. Primero, `fit` ajusta la ecuacion a los datos, en este caso calcula $X_{\\sigma}$. Luego `transform` transforma los datos aplicando la ecuacion. Este proceso nos devuelve los datos __preprocesados__ en la variable `X_train_norm`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4242b-da2a-43e0-8fb4-372f42835fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2de1ba7-c2aa-4427-b565-af263880675e",
   "metadata": {},
   "source": [
    "Notemos que los valores de `X_train_norm` estan transformados de acuerdo al rango $(a,b)$ previamente definido. Para comprobarlo, imprimamos los valores maximos y minimos con las funciones `max` y `min`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5ea17d-c843-4cf2-af45-5d78a6cb6321",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Max value {}'.format(X_train_norm.max()))\n",
    "print('Min value {}'.format(X_train_norm.min()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24ec344-43c3-475a-92c8-1928def1bfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecb9b3-15d2-468d-9d3d-5cf8cf150571",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ef374b-2f63-48cc-8fac-5d200c2498ae",
   "metadata": {},
   "source": [
    "## 4. Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b805a31-5528-42db-b608-a5dd2870503f",
   "metadata": {},
   "source": [
    "En esta secci√≥n, vamos a aplicar una red de autocodificador __(autoencoder)__. Primero comenzaremos definiendo que es un __autoencoder__. Para ello, definamos $h_{\\Theta}$ como el __autoencoder__, donde $\\Theta$ representa los parametros del modelo. En este contexto, para una entrada $X$, el objetivo del __autoencoder__ es:\n",
    "\n",
    "$$\n",
    "h_{\\Theta}(X) = d(e(X)) = \\hat X\n",
    "$$\n",
    "\n",
    "Donde $e(X)$ y $d(e(X))$ estan compuestos por capas y son conocidos como encodificador (__encoder__) y decodificador (__decoder__) respectivamente. La funcion de $e(X)$ consiste en reducir las dimensiones de $X$ hasta llegar a la maxima compresion en la capa de codigo (__code__), donde se obtiene una __representacion encodificada__ $E$. Esta representacion $E$ es usada por $d(E)$ para reconstruir la entrada original $X$ tal que $d(E) = \\hat X$.\n",
    "\n",
    "Para ilustrar mejor este proceso, vamos a definir un __autoencoder__ para nuestro dataset. Para ello, observamos la siguiente figura:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb4a36b-0571-4034-8c83-f0af720b00f0",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/aguilarls/practicas/main/Algebra-computarizada/images/autoencoder.png\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97a6cc-8ec2-4b97-b55d-7c9cb4cb9545",
   "metadata": {},
   "source": [
    "Como podemos apreciar, tenemos de entrada $X$ una imagen compuesta por `28 * 28` pixels. Comenzemos a definir la arquitectura:\n",
    "\n",
    "__1. Encoder:__ Para poder usar esta representacion, vamos a convertir nuestros datos de matrix en un vector: `28 * 28 = 784`. De esta manera, nuestra capa de entrada cuenta con `784` unidades. A continuacion definiremos una capa oculta. Para el numero de neuronas consideraremos la reduccion de `8` pixels de la imagen orginal $X$, esto se traduce en: `20 * 20 = 400` unidades. Ahora procederemos a definir el __code__.\n",
    "\n",
    "__2. Code:__ A continuacion vamos a definir las unidades del __codigo__, para ello vamos a reducir `10` pixeles, obteniendo: `10 * 10 = 100` unidades. Como siguiente paso procederemos con el __decoder__.\n",
    "\n",
    "__3. Decoder:__ Para el proceso de construccion del __decoder__ vamos a usar el mismo numero de capas y neuronas del __encoder__ pero de forma invertida. De ese modo, la primera capa tendria: `20 * 20 = 400` unidades. Finalmente, la capa de salida contendria: `28 * 28 = 784` unidades.\n",
    "\n",
    "Es importante notar que, tanto la entrada del __decoder__ como la salida del __encoder__ deben de coincidir en el numero de __neuronas__. Finalmente, como funcion de activacion vamos a usar relu:\n",
    "$$\n",
    "x = max(0, x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c87c7a5-9bac-4664-bd0e-d526a4bb84aa",
   "metadata": {},
   "source": [
    "Durante la implementacion de su `autoencoder` puede usar el numero de `neuronas` y `capas` que considere necesario con la siguiente __condiciones:__\n",
    "1. El numero de neuronas de su capa de entrada (`input_size`) debe de coincidir con el numero de salida (`output_size`).\n",
    "2. Con el fin de visualizar su __code__, debe utilizar las mismas dimenciones para al `ancho` y `alto`, por ejemplo consideremos `7` pixels de `ancho` y `largo`, para este caso tendria un total de `7 * 7 = 49` neuronas en su __code__.\n",
    "3. Como funcion de activacion debe de usar `relu`.\n",
    "\n",
    "Como sugerencia se le recomienda realiazar las mismas reducciones al `largo` y `ancho` de la imagen en su `encoder`. Por ejemplo, para un `encoder` con 3 capas: `28 * 28 = 784` -> `25 * 25 = 625` -> `23 * 23 = 529`. Recuerde usar `variables` para representar el numero de neuronas en sus capas.\n",
    "\n",
    "__Note__ que la funcion `eval_autoencoder` evaluara si su arquitectura esta correcta, se le recomienda no proceder con el ejercicio y/o realizar las correciones necesarias si hubiese algun error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "badc36ab-24c3-4488-80b6-da6097e1df45",
   "metadata": {},
   "source": [
    "A continuacion, definira su modelo, recuerde que __debe__ agregar capas, la cantidad dependera de usted. Las siguientes `variables` se le han proporcionado:\n",
    "* __input_size__: Dimensiones de entrada.\n",
    "* __n_code__: Dimensiones de su code.\n",
    "* __output_size__: Dimensiones de salida.\n",
    "* __activation_f__: Funcion de activacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e416ed19-c130-4cad-96b6-b3f5c4da985c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder model\n",
    "input_size = ...   # 28 * 28\n",
    "\n",
    "n_code = ...    \n",
    "\n",
    "output_size = ... # 28 * 28\n",
    "activation_f = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7560313b-1838-4f8d-b758-5750d8697174",
   "metadata": {},
   "source": [
    "Debido a que usaremos tuplas, agruparemos las capas en el orden adecuado. Para ello usaremos la variable `hidden_layers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ae418-5344-4154-9c8f-820c83528f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layers = (...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b05c86d-fb62-4c32-ab17-5a51de5c793c",
   "metadata": {},
   "source": [
    "Si queremos construir un __autoencoder__ con m√°s capas, podemos agregarlas usando variables, por ejemplo: `hidden_layers = (input_size, encoder_size_1, encoder_size_2, ..., n_encoded, decoder_size_1, decoder_size_2, ..., output_size)`. Tenga en cuenta que `input_size` debe tener las mismas dimensiones que `otput_size`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cf7b1c-ce06-42a3-8335-fc9d215e1ba7",
   "metadata": {},
   "source": [
    "Para la construccion del __autoencoder__ usaremos la clase [MLPRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn-neural-network-mlpregressor) de `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee167e2c-fd05-458b-99ce-cb63f826edfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3b8367-9837-46c8-b5c7-af21e615ab47",
   "metadata": {},
   "source": [
    "A continuacion definira los `epochs` y el ratio de aprendizaje `lr`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff077fe-29da-4099-b3f3-888ef8a94a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training hyper-params\n",
    "epochs = ...\n",
    "lr = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dea9e5-912b-4bec-80d6-465a4f22617a",
   "metadata": {},
   "source": [
    "La clase `MLPRegressor` le permite crear una red neuronal. Para este caso, debe de completar los siguientes argumentos:\n",
    "1. `hidden_layer_sizes`: Representa el numero de capas y neuronas de su red definidas por la variable: `hidden_layers`.\n",
    "2. `max_iter`: Denota el numero maximo de `epochs`.\n",
    "3. `learning_rate_init`: Especifica el ratio de aprendizaje `lr`.\n",
    "4. `activation`: Representa la funcion de activacion `activation_f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1971777f-7219-4b69-9533-f61a61a33cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_encoder = MLPRegressor(hidden_layer_sizes = ...,\n",
    "                            max_iter = ..., \n",
    "                            learning_rate_init = ...,\n",
    "                            activation = ...,\n",
    "                            verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2293870-fd82-462b-bd8b-a2a00f0cfc79",
   "metadata": {},
   "source": [
    "Antes de proceder, nos aseguraremos de que nuestra arquitectura este correcta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e382ba5-85a0-4205-b4c7-b500ab45afe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_autoencoder(auto_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4275d5-b768-4018-8375-5ee05fd5891f",
   "metadata": {},
   "source": [
    "Para corregir los errores, proceda a modificar y/o ejecuar la __arquitectura__ definida en:\n",
    "```python\n",
    "# autoencoder model\n",
    "input_size = ...   # 28 * 28\n",
    "\n",
    "n_code = ...    \n",
    "\n",
    "output_size = ... # 28 * 28\n",
    "activation_f = ...\n",
    "```\n",
    "Para aplicar los cambios ejecute las celdas con las variables `hidden_layers` y `auto_encoder`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7de470b-b033-4a0f-8bb6-17ced7652368",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "2. Pregunta: Describa en detalle su arquitectura. Cuantas unidades decicio usar en el code y por que?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112dde8d-8442-48e5-97bc-d8e7fad0890a",
   "metadata": {},
   "source": [
    "Para el entrenamiento, usaremos los datos __preprocesados__ `X_train_norm` como $(X,y)$, ya que deseamos aprender a reconstruir los datos originales $X$, la entrada y salida son las mismas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df165d9-503f-4859-ba73-1efa4eee7eed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "auto_encoder.fit(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14923985-16b4-472c-8363-3ba3309f0bbd",
   "metadata": {},
   "source": [
    "Podemos observar como ha ido evoluacionando el loss con el siguiente grafico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaea92a-13cf-40a9-b5a3-85ba5f7e1531",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss(auto_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35871d0-99e7-4948-893b-5a4701f986da",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "3. Pregunta: Cual fue el loss minimo que alcanzo su autoencodificador, y en cuantas iteraciones? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4744e92-0df8-4fe2-831b-5dcaa7bf9a25",
   "metadata": {},
   "source": [
    "Una vez entrenado el autoencodificador, vamos a realizar algunas predicciones. Ejecute la siguiente celda las veces necesarias para generar predicciones. Note que de entrada se encuentra una imagen en la izquierda (__Input image__), la imagen del centro contiene el __Code representation__, es decir la representacion comprimida de su modelo. Finalmente, el decodificador usa el __code__ para reconstruir nuevamente la imagen (__reconstructed image__)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee59b8-c282-4acf-9e04-6fdfc9d328a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_prediction(X_train_norm, auto_encoder, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad62c3e3-e55a-4ab5-b088-01b61c16a810",
   "metadata": {},
   "source": [
    "En la imagen, tenemos como entrada un $X$ original que representa un numero. El grafico del centro muestra la representacion $E$ obtenida por el __codigo__. Finalmente la imagen de la derecha muestra $X^{'}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3feb28fb-4c2b-4cba-a117-bec616d9c6bb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b9caa2-b17f-46d5-81bb-e28d63680d70",
   "metadata": {},
   "source": [
    "## 5. UMAP como alternativa a PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4cbf3-5433-47ee-8f71-10d191678fed",
   "metadata": {},
   "source": [
    "Tanto `UMAP` como `PCA` se pueden utilizar para la reducci√≥n dimensional. Por ejemplo, sea $X^{(m,n)}$ una matriz de entrada donde $m$ y $n$ representan el total de filas y columnas respectivamente. Asimismo, sea $z$ una nueva dimensi√≥n tal que $z < n$. Aplicando `UMAP` o `PCA` sobre la estructura original $X^{(m,n)}$ obtendremos una nueva matriz $X^{(m,z)}$. Dado que tanto `UMAP` como `PCA` guardan informaci√≥n sobre la estructura original $X^{(m,n)}$, es posible realizar la operaci√≥n __inversa (reconstruccion)__, es decir: $X^{(m,n)} \\rightarrow X^{(m,z)}$.\n",
    "\n",
    "Por supuesto, ambos algoritmos usan __diferentes m√©todos__ para transformar e invertir tales transformaciones, siendo `UMAP` el mas complejo. Otro caso de uso es la visualizaci√≥n. Por ejemplo: $X^{(m,100)} \\rightarrow X^{(m,2|3)}$. En esta secci√≥n vamos a transformar y visualizar los datos generados por nuestro __encoder__ $E$ usando ambos algoritmos tal que: $E^{(m,n)} \\rightarrow E^{(m,2)}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b8ee290-9776-46ac-99e3-06fbfeb3cc92",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "4. Pregunta: Para un dataset $X^{(m,n)}$, el proceso de reduccion a una nueva dimension $z$ debe garantizar que:\n",
    "    <li>$z>=n$.</li>\n",
    "    <li>$z>n$.</li>\n",
    "    <li>$n=z$.</li>\n",
    "    <li>$n<z$.</li>\n",
    "    <li>$z<n$.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0ec5e-af77-4e5a-ac99-e6f35f9c5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e565295-ede2-4792-ad51-ccb705a94653",
   "metadata": {},
   "source": [
    "Primero obtendremos $E$, para ello usaremos el __encoder__ que nos devolvera los datos en la variable `encoded_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ba86e-3209-4d68-8658-6568b25439dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data = encoder(X_train_norm, auto_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4a795-7c1e-4e2f-9e63-369cbfb06d61",
   "metadata": {},
   "source": [
    "Como podemos comprobar, $E$ contiene la representacion comprimida de todos los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f5a64e-d771-42c7-adc5-b68d1cdc41b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3290a71-e335-440a-9d9f-5d7ad1b7f99e",
   "metadata": {},
   "source": [
    "Para este ejercicio vamos a reducir las dimensiones a 2: $E^{(m,n)} \\rightarrow E^{(m,2)}$. Para ello, definiremos una variable llamada `new_dims` con las nuevas dimensiones reducidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6ca63-ead8-4f5a-a626-dae86b14881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dims = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48354d7-dd7f-4b3f-bfb3-fee3655e93e6",
   "metadata": {},
   "source": [
    "Tanto `UMAP` como `PCA` tienen un argumento llado `n_components`, el cual indica a cuantas dimensiones se va a convertir. Para nuestro caso definiremos: `n_components = new_dims`. Asimismo, el argumento `random_state` nos permite obtener resultados reproducibles, para este caso, asignaremos el valor de `5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fc95ab-9ec2-4759-ae9e-8bcabc81efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap = UMAP(n_components = ..., random_state = ...)\n",
    "pca = PCA(n_components = ..., random_state = ...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf77a10-a38b-465c-ba38-991a1f1146cb",
   "metadata": {},
   "source": [
    "Ahora procederemos a entrenar y transformar $E$. Para ello proporcionaremos como entrada la variable `encoded_data` a `UMAP` y `PCA`. Asimismo definiremos dos variables: `dims_umap` y `dims_pca` para guardar $E$ con las nuevas dimensiones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad34809-bc44-4b80-9cdf-b551ae9fb58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_umap = umap.fit_transform(...)\n",
    "dims_pca = pca.fit_transform(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d246e35-7d0c-4996-ad46-83497cbff33e",
   "metadata": {},
   "source": [
    "Inspeccionemos las nuevas dimensiones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e4f53d-13c2-4c69-9a16-4a3a4f554d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original encoded data E: {}'.format(encoded_data.shape))\n",
    "print('UMAP reduced data E: {}'.format(dims_umap.shape))\n",
    "print('PCA reduced data E: {}'.format(dims_pca.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d71434-85c0-4dff-8bd2-8ff5dbfcb102",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "5. Pregunta: Siendo $E^{(m,z)}$ el nuevo espacio generado por UMAP, donde $z=2$ y $E^{(m,n)}$ la dimension original. En el proceso de reduccion se cumple:\n",
    "    <li> $E^{(m,n)} \\rightarrow E^{(m,z)}$.</li>\n",
    "    <li> $E^{(m,n)} \\rightarrow E^{(m,n)}$.</li>\n",
    "    <li> $E^{(n,m)} \\rightarrow E^{(n,m)}$.</li>\n",
    "    <li> $E^{(n,z)} \\rightarrow E^{(n,z)}$.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d518059-e12a-4c0c-997e-6d0a249c212c",
   "metadata": {},
   "source": [
    "Como se puede observar, el numero de filas `m` se mantiene en todos los casos. Sin embargo, el numero de columnas para `UMAP` y `PCA` ha cambiado de $n \\rightarrow 2$. Como tenemos $2$ dimensiones, procedamos a relizar algunas visualizaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84733fd1-0faa-4ecc-a502-ea240abcfae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_embeddings(dims_umap, dims_pca, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc8ef3d-37bf-447a-9f71-58726535e141",
   "metadata": {},
   "source": [
    "Como habiamos comentado antes, `UMAP` es mas complejo que `PCA`, procedamos ahora a realizar una visualizacion mas compleja de las relaciones entre las distancias del espacio obtenido por `UMAP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bcc1745-4da5-49f4-81f7-33601d9ac2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap.plot as plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dfdd6c-158f-4571-b70f-a3f6624da24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.connectivity(umap, show_points=True, labels = targets);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b156549-3f5b-45d1-ab7c-bd5923b5c406",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "6. Pregunta: Analizando los espacios obtenidos por UMAP y PCA, que diferencias significativas podria mencionar.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f40660-56bf-495f-abc0-3d7e4519887a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b84527-8f27-4af7-be35-2778ab6aaa6b",
   "metadata": {},
   "source": [
    "## 6. Transformaciones inversas en UMAP (de 2D a n):"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48979fd3-0c3e-4621-a3c1-02decfc19c6a",
   "metadata": {},
   "source": [
    "Como mencionamos en la __seccion 5__ una vez que `UMAP` u `PCA` __aprenden__ a como representar $X^{(m,n)}$ en un __espacio__ $z$; es posible volver al __espacio original__ `n`, tal que: $X^{(m,z)} \\rightarrow X^{(m,n)}$. A este proceso se le conoce formalmente como __reconstruccion__ o __transformacion inversa__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d1a729-8118-4298-9aed-c26cc5330476",
   "metadata": {},
   "source": [
    "En esta seccion vamos a realizar una __transformacion inversa__ con `UMAP`. Para ello, seleccionaremos un digito del dataset en la variable `n_class`. Recordemos que solo contamos con digitos en el intervalo $[0,9]$. Una vez completada la __seccion 7__, se le recomienda volver a esta seccion y probar con otros digitos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e132d25-2150-4422-a030-68611c22c9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_class = ...\n",
    "sample, indx = get_sample(n_class, dims_umap, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9d485e-94d6-47d0-a0b7-6192ec5ecb49",
   "metadata": {},
   "source": [
    "Ahora procedamos a inspeccionar el digito en la variable `sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0448cda3-3cfc-4cdd-aceb-3b203d845f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305a29c9-eecb-442a-9ff8-ec664913fddb",
   "metadata": {},
   "source": [
    "Como podemos observar contamos con un punto en 2D. Procedemos ahora a visualizar nuestra muestra en el espacio 2D de `UMAP`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04b030c-3a83-4f9d-813a-d7f49e4f24bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sample(sample, dims_umap, targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b853e68c-ba22-4bd8-b863-1dcaf9891f85",
   "metadata": {},
   "source": [
    "Para realizar la operacion __inversa__, usaremos como entrada `sample` y generaremos las dimensiones originales en $E$. Para ello usaremos el comando `umap.inverse_transform(sample)`. Note que los resultados seran alamcenados en la variable `transform_sample`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846d50e5-28e0-404b-b579-906ca96354f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform inverse UMAP\n",
    "transform_sample = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bedcdae-a200-46f1-b861-dfbbec4e84f0",
   "metadata": {},
   "source": [
    "Una vez transformado, procedamos a comprobar las dimensiones de la variable `transform_sample`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36c28cc-bb5f-4343-87ec-4fae3c5284f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Umap sample 2D-points: {}'.format(sample.shape))\n",
    "print('Umap sample inverse transform: {}'.format(transform_sample.shape))\n",
    "print('Original encoded data E: {}'.format(encoded_data[indx, :].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eaf6d1-b026-4c38-919e-ac577323ec4b",
   "metadata": {},
   "source": [
    "<div class=\"alert-info\">\n",
    "7. Pregunta: Siendo $s^{(m,z)}$ el vector sample, donde $z<n$ y $S$ el espacio original. En el proceso de transformacion inversa se cumple:\n",
    "    <li> $s^{(m,z)} \\rightarrow S^{(m,z)}$.</li>\n",
    "    <li> $s^{(m,z)} \\rightarrow S^{(m,n)}$.</li>\n",
    "    <li> $s^{(m,z)} \\rightarrow S^{(n,n)}$.</li>\n",
    "    <li> $s^{(m,z)} \\rightarrow S^{(m,z)}$.</li>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867c86c-9e37-4738-a75f-3a8937be0ede",
   "metadata": {},
   "source": [
    "## 7. Generacion de numeros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7355b2-7113-440c-b557-c98117e53e58",
   "metadata": {},
   "source": [
    "Como hemos podido observar hemos sido capaces de convertir las dimensiones de $n \\rightarrow 2$ y viceversa de $2 \\rightarrow n$ usando `UMAP`. En esta seccion vamos a usar los datos de la seccion anterior para generar numeros usando el __decoder__. La idea para esta seccion consiste en usar la muestra en 2D de la variable `sample` para generar una imagen con el __decoder__. Sin embargo, recordemos que `sample` contiene solo $2$ dimensiones, mientras que el __decoder__ espera como entrada $n$. Es alli donde usaremos la __transformacion inversa__ de `UMAP` en `sample` para generar $2 \\rightarrow n$. Esta transformacion se encuentra guardada en la variable `transform_sample` de la seccion anterior. La siguiente l√≠nea realizar√° el m√©todo que acabamos de describir:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9cf5ca-ba68-4119-8284-c4777ebe3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_transformation(sample, transform_sample, dims_umap, targets, n_class, auto_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d920cdf-faec-4688-ae30-aa92e6ceeb68",
   "metadata": {},
   "source": [
    "Notemos que el numero que obtengamos esta definido por la variable `n_class`, si deseamos usar otro numero, tenemos que ejecutar el codigo desde la seccion anterior. Como se puede apreciar hemos generado un numero usando la reconstruccion inversa de `UMAP`. Procedamos ahora a comparar el numero generado usando los datos $E$ y los generados por `UMAP`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c410a28-d58b-4b54-9b1d-c9929cf7c24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comparison(encoded_data, transform_sample, auto_encoder, targets, indx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c616ab9a-6a07-4170-93e9-50b16ffa4406",
   "metadata": {},
   "source": [
    "Ahora, exploremos qu√© tipos de n√∫meros puede generar nuestro __decodificador__. Para hacerlo, pasaremos todos los datos $E$ que contienen nuestro n√∫mero seleccionado en la variable `n_class`. Usando estos datos vamos a generar un __subconjunto__ de muestras del n√∫mero en `n_class`. Finalmente, usando la representacion 2D de `UMAP`, exploraremos en el espacio de UMAP, esto nos mostrar√° c√≥mo el n√∫mero en `n_class` puede mutar en diferentes n√∫meros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9691e03-0055-428b-b517-4e93601f3053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_space(dims_umap, encoded_data, n_class, targets, auto_encoder, umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6a09c8-c442-45f1-a223-2b939f645bdc",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
