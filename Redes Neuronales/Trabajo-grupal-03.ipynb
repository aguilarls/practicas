{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5a3e3b4",
   "metadata": {},
   "source": [
    "# Librerias\n",
    "Antes de proceder, necesitamos instalar las librerias necesarias. En nuestro caso, trabajaremos con la Libreria __[scikit-learn](https://scikit-learn.org/stable/index.html)__ en su version __0.24.2__. Esta libreria ofrece una amplia gama de algoritmos y/o tecnicas aplicadas no solo a la inteligencia artificial, sino tambien a otras areas como ciencia de datos. Para poder instalar nuestra libreria en la maquina virtual procederemos a ejecutar el siguiente comando: `!pip install -U scikit-learn==0.24.2`. La ejecucion puede tardar unos momentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c019ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalacion de libreria\n",
    "!pip install -U scikit-learn==0.24.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd18501",
   "metadata": {},
   "source": [
    "# I. Practica-1: tic-tac-toe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d283639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerias\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import numpy as np\n",
    "# data sets\n",
    "from sklearn.datasets import fetch_openml\n",
    "# division de datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "# pre-procesamiento\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "# red neuronal\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec61e6d",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda para comprobar que tiene instalada la version de __sklearn 0.24.2__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f633856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobar version\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "# Nota: asegurese de que la version sea: 0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7697a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# descargar data set\n",
    "raw = fetch_openml(name = 'tic-tac-toe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e0e696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraer datos\n",
    "dataset = raw['data'].copy()\n",
    "# extraer target y\n",
    "dataset['y'] = raw['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc231699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1. Imprima el total de filas y columnas\n",
    "################# Ingrese su codigo en esta celda #####################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eac4f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2. Muestre por medio de codigo el nombre de columnas\n",
    "################# Ingrese su codigo en esta celda #####################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7127f7c9",
   "metadata": {},
   "source": [
    "__Hint:__ El comando `print` es usado para imprimir resultados. Por ejemplo `print(5)` imprime el numero 5. Cuando se crea un __dataset__, existen dos propiedades que se pueden acceder mediante `.`, por ejemplo `dataset.shape` y `dataset.columns`, donde `shape` representa las dimensiones (filas y columnas) y `columns` muestra las columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf558a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ejecute la celda para visualizar la distribucion de targets\n",
    "labels, counts = np.unique(dataset['y'].values, return_counts = True)\n",
    "plt.bar(labels, counts, align = 'center')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f697c6",
   "metadata": {},
   "source": [
    "### 1. Pregunta: El siguiente plot muestra la distribucion de los targets. Como se observa existe un desbalance de clases.\n",
    "* Como podria afectar este fenomeno al aprendizaje de la red\n",
    "* Que enfoque podriamos usar para mitigar el desbalance. Describa en detalle y justifique su funcionamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6227fd8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42515dc",
   "metadata": {},
   "source": [
    "# II. Mapeo\n",
    "En el ejemplo de clase usamos la siguiente configuracion para mapear los valores en nuestro data set a valores numericos:\n",
    "* __x__: 1\n",
    "* __o__: 0\n",
    "* __b__: -1\n",
    "* __positive__: 1\n",
    "* __negative__: 0\n",
    "\n",
    "Para ello creamos un diccionario llamado __valores_de_mapeo:__\n",
    "```python\n",
    "valores_de_mapeo = {'x': 1, 'o': 0, 'b': -1, 'positive': 1, 'negative': 0}\n",
    "```\n",
    "En esta seccion definira nuevos valores numericos para cada elemento. Recuerde que los elementos: __x, o, b__ deben de tener valores diferentes entre si. Por ejemplo si asigna 100 a __x__ (`valores_de_mapeo = {'x': 100, ...}`), los valores para __o__ y __b__ deben ser diferentes de 100. Finalmente __asegurese de mapear valores para los targets positive y negative como 1 y 0 respectivamente__. En la siguiente celda cambie el valor de la variable `valores_de_mapeo` reemplazando los `...` por su codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63ebde7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Defina un diccionario de mapeo de valores\n",
    "################# Ingrese su codigo en esta celda #####################\n",
    "valores_de_mapeo = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a08eb1",
   "metadata": {},
   "source": [
    "Ejecute las siguientes celdas una vez que haya definido sus valores de mapeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95d94eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformacion\n",
    "funcion_de_mapeo = {}\n",
    "for column in dataset.columns:\n",
    "    funcion_de_mapeo[column] = valores_de_mapeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb0b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aplicacion de la funcion de mapeo al data set\n",
    "dataset.replace(funcion_de_mapeo, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c442cca0",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda para comprobar sus resultados. Debe ser capaz de visualizar el data set con los nuevos valores asignados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e829b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1482cc",
   "metadata": {},
   "source": [
    "### 2. Pregunta: Que criterio uso para los valores de mapeo?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ddf67",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4dcd9b",
   "metadata": {},
   "source": [
    "# III. Division de datos\n",
    "En esta seccion dividiremos el data set en dos grupos: __Entrenamiento__ y __Test__. Usaremos los datos de entrenamiento para alimentar a nuestra red neuronal. Una vez completado el entrenamiento, procederemos a evaluar el modelo usando los datos de __Test__. Para la divicion usaremos las siguientes variables:\n",
    "* __X_train:__ Datos de entrenamiento.\n",
    "* __y_train:__ Targets de los datos de entrenamiento.\n",
    "* __X_test:__ Datos de test.\n",
    "* __y_test:__ Target de los datos de test.\n",
    "\n",
    "Recordemos que en clase usamos el comando `train_test_split(...)` con la siguiente configuracion:\n",
    "```python\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset[columnas], dataset['y'], test_size = 0.2, random_state = 1)\n",
    "```\n",
    "Para esta ocacion, vamos a agregar un parametro extra: `stratify = dataset['y']`. Este parametro tratara de __balancear__ la division de clases teniendo en cuenta la cantidad de las mismas. La idea es crear una distribucion mas __uniforme__. Reservaremos un __10% para los datos de Test__.\n",
    "\n",
    "__Nota:__ Asigne  una __semilla__ a `random_state` con valor igual a __1__. Para especificar el porcentaje de los datos de test use el parametro `test_size` especificando valores de porcentajes. En el ejemplo, `test_size = 0.2` representa un __20%__ de datos de test, si se reemplaza por `test_size = 0.15` representaria __15%__. Recuerde reemplazar los `...` en su codigo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ded9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seleccionaremos las columnas sin targets\n",
    "columnas = list(dataset.columns[:-1])\n",
    "print(columnas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f7d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Ingrese su codigo aqui #####################\n",
    "# 3.1. Divida los datos en los bloques mencionados.\n",
    "X_train, X_test, y_train, y_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526704af-e7ae-4abc-9a9d-8fed1d8edf79",
   "metadata": {},
   "source": [
    "Ejecute la siguiente celda para verificar sus resultados. Dede de obtener el resultado: `(862, 9)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b61ac-815f-4edf-a5cc-f44ebd66f9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fbbc9f7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6633d700",
   "metadata": {},
   "source": [
    "# IV. Pre-procesamiento\n",
    "Antes de entrenar nuestra red neuronal, necesitamos pre-procesar los datos. Este es un paso __necesario__. Aplicaremos el pre-procesamiento a los datos de __entrenamiento (X_train)__ y luego a los datos de __test (X_test)__. Para esta seccion vamos a elejir de una lista de __3 tipos de pre-procesamiento__. A continuacion encontrara una lista detallando cada uno de ellos:\n",
    "* StandardScaler: Aqui las columnas se estandarizan usando: $z = (x - \\mu) / s$. Donde x representa los datos, $\\mu$ es la media y $s$ la desviacion estandar. Consulte mas detalles de uso [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler).\n",
    "* MinMaxScaler: Transforma las columnas al escalarlas a un rango seleccionado. El calculo es dado por: $x = s * (max - min) + min$, donde $s = (x - x_{min} / (x_{max} - x_{min}))$ y __max__ y __min__ son intervalos dados. Consulte mas detalles de uso [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
    "* MaxAbsScaler: Escala cada columna usando su valor absoluto. Consulte mas detalles de uso [aqui](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MaxAbsScaler.html#sklearn.preprocessing.MaxAbsScaler).\n",
    "\n",
    "Como se vio en clase, para el pre-procesamiento se uso __StandardScaler__ de la siguiente manera:\n",
    "```python\n",
    "# crear scalador\n",
    "scaler = StandardScaler()\n",
    "# aplicar SOLO A DATOS DE ENTRENAMIENTO\n",
    "scaler.fit(X_train)\n",
    "# transformar datos de entrenaminto\n",
    "X_train = scaler.transform(X_train)\n",
    "# transformar datos de test\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "Para poder cambiar por otro pre-procesamiento, cambie la clase: `StandardScaler()` por `MinMaxScaler()` o `MaxAbsScaler()`. Por ejemplo para `MinMaxScaler()`:\n",
    "\n",
    "```python\n",
    "scaler = MinMaxScaler()\n",
    "# aplicar SOLO A DATOS DE ENTRENAMIENTO\n",
    "scaler.fit(X_train)\n",
    "# transformar datos de entrenaminto\n",
    "X_train = scaler.transform(X_train)\n",
    "# transformar datos de test\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "\n",
    "Para `MaxAbsScaler()`:\n",
    "\n",
    "```python\n",
    "scaler = MaxAbsScaler()\n",
    "# aplicar SOLO A DATOS DE ENTRENAMIENTO\n",
    "scaler.fit(X_train)\n",
    "# transformar datos de entrenaminto\n",
    "X_train = scaler.transform(X_train)\n",
    "# transformar datos de test\n",
    "X_test = scaler.transform(X_test)\n",
    "```\n",
    "__Nota:__ Recuerde asignar el pre-procesamiento a la variable __scaler__, ej: `scaler = StandardScaler()`, `scaler = MinMaxScaler()` o `scaler = MaxAbsScaler()` respectivamente. En la siguiente asigne un pre-procesamiento a la variable `scaler` (remueva los `...`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Ingrese su codigo aqui #####################\n",
    "# 4.1. Asigne un pre-procesamiento\n",
    "scaler = ...\n",
    "# aplicar SOLO A DATOS DE ENTRENAMIENTO\n",
    "...\n",
    "# transformar datos de entrenaminto\n",
    "X_train = ...\n",
    "# transformar datos de test\n",
    "X_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07441b59",
   "metadata": {},
   "source": [
    "### 3. Pregunta: Jusfifique la eleccion del tipo de pre-procesamiento usado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72dd1b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0a4ac",
   "metadata": {},
   "source": [
    "# V. Creacion de Red Neuronal\n",
    "\n",
    "<div align=\"center\">\n",
    "<img src=\"https://raw.githubusercontent.com/aguilarls/practicas/main/Redes%20Neuronales/images/red-03.png\" />\n",
    "</div>\n",
    "\n",
    "Usualmente, cuando se define una red se habla de __arquitectura__. En ese sentido, la arquitectura de la red representa componentes de la misma. En esta seccion implementara la red neuronal mostrada en el diagrama. Para ello debera crear las capas ocultas. Como se observa existen __dos capas ocultas__ compuestas por __50 neuronas__ cada una. Para la creacion de la red usaremos la clase: [MLPClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn-neural-network-mlpclassifier). Para poder especificar el numero de capas ocultas y neuronas usaremos una __tupla__. En programacion la __tupla__ es una estructura usada para representar informacion. En python se definen mediante `()`:\n",
    "```python\n",
    "capas_ocultas = (15, 10)\n",
    "```\n",
    "En el ejemplo, estamos definiendo una tupla, que contiene 2 elementos. El primero es el valor __15__, y el segundo __10__. De este ejemplo se deduce que en la primera capa oculta existen __15 unidades__ y __10 en la segunda__. Para el caso de la red, especificaremos las capas ocultas con el comando: `hidden_layer_sizes = capas_ocultas`. Asimismo usaremos el comando `max_iter` para definir el __numero de iteraciones__. Finalmente, definiremos el comportamiento aleatorio con `random_state = 1`. En el siguiente bloque tendra que asignar los valores descritos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5889c683-9d12-4b7d-9d99-c3b82627c4ca",
   "metadata": {},
   "source": [
    "En la siguiente celda defina las capas ocultas en la variable `capas_ocultas`. Asimismo asigne un numero de iteraciones en la variable `iteraciones`. Recuerde remover los `...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Ingrese su codigo aqui #####################\n",
    "# 5.1. Defina la arquitectura de su red neuronal\n",
    "capas_ocultas = ...\n",
    "iteraciones = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creacion de la red\n",
    "red_neuronal = MLPClassifier(random_state = 1, max_iter = iteraciones, hidden_layer_sizes = capas_ocultas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0348053",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Ingrese su codigo aqui #####################\n",
    "# 5.2. Inspeccione los parametros de la red\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386531c-8672-432a-9f9a-dde80172c9be",
   "metadata": {},
   "source": [
    "__hint:__ El comando: `red_neuronal.get_params()` muestra la lista de atributos de su red. El ratio de aprendizaje se suele tambien llamar __learning_rate_init__, y el optimizador __solver__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c89429",
   "metadata": {},
   "source": [
    "### 4. Pregunta: Cuales son el ratio de aprendizaje y optimizador usados por su red?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69faf6dd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501760b8",
   "metadata": {},
   "source": [
    "# VI. Entrenamiento\n",
    "En esta seccion entrenaremos la red neuronal con los los datos pre-procesados. Para entrenar la red, necesitamos llamar al comando:\n",
    "```python\n",
    "red_neuronal.fit(X_train, y_train)\n",
    "```\n",
    "Donde __X_train__ e __y_train__ representan los datos de entrenamiento y/o targets. De manera general, la funcion `fit(X, y)` espera que el primer argumento sean los datos y el segundo los targets. En la siguiente celda implemente el entrenamiento de la red."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "169289a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Ingrese su codigo aqui #####################\n",
    "# 6.1. Entrene la red \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d58f1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e15c5b",
   "metadata": {},
   "source": [
    "# VII. Predicciones\n",
    "Una vez completada la fase de entrenamiento, vamos a realizar algunas predicciones. Para ello, solo necesitaremos proporcionar datos al modelo. Para este ejemplo vamos a usar la primera fila de los datos de entrenamiento: `X_train_scaler[:1]`. Ahora, en este caso, disponemos de dos formas de visualizar las predicciones: probabilidades y targets. Si usamos probabilidades tendriamos:\n",
    "```python\n",
    "red_neuronal.predict_proba(X_train[:1])\n",
    "```\n",
    "Mientras que si usamos los targets el resultado seria:\n",
    "```python\n",
    "red_neuronal.predict(X_test[:1])\n",
    "```\n",
    "Podemos verificar los resultados observando los primeros valores de los targets de entrenamiento y test con `y_train[0]` e `y_test[0]`\n",
    "```python\n",
    "print(y_train.values[0])\n",
    "```\n",
    "\n",
    "```python\n",
    "print(y_test.values[0])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9366cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de la primera fila (datos de entrenamiento)\n",
    "print(red_neuronal.predict_proba(X_train[:1]))\n",
    "# Valor de target de la primera fila (datos de entrenamiento)\n",
    "print(red_neuronal.predict(X_train[:1]))\n",
    "# Verificar valor real del target (datos de entrenamiento) \n",
    "print(y_train.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821f4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probabilidades de la primera fila (datos de test)\n",
    "print(red_neuronal.predict_proba(X_test[:1]))\n",
    "# Valor de target de la primera fila (datos de entrenamiento)\n",
    "print(red_neuronal.predict(X_test[:1]))\n",
    "# Verificar valor real del target (datos de entrenamiento) \n",
    "print(y_test.values[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583a8316",
   "metadata": {},
   "source": [
    "### 5. Pregunta: Coincidieron las predicciones para los datos de entrenamiento y test?. Describa una hipotesis acerca del comportamiento observado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4f947",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceefdd58",
   "metadata": {},
   "source": [
    "# VIII. Evaluacion\n",
    "Una vez entrenado el modelo, podemos realizar predicciones, no obstante, necesitamos __evaluar__ la __presicion (accuracy)__ de las predicciones. Para ello usaremos los datos de entrenamiento y test conjuntamente con los targets. Para ello usaremos el comando `score`. Para los datos de entrenamiento:\n",
    "```python\n",
    "red_neuronal.score(X_train, y_train)\n",
    "```\n",
    "Ahora para test:\n",
    "```python\n",
    "red_neuronal.score(X_test, y_test)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef21f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy para entrenamiento\n",
    "print(red_neuronal.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8babe0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "################# Ingrese su codigo aqui #####################\n",
    "# 8.1. Imprima el accuracy para test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b08cae",
   "metadata": {},
   "source": [
    "### 6. Pregunta: Cuales son los porcentajes de accuracy para los datos de entrenamiento y test?. Explique el comportamiento observado elaborando una hipotesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2da1f2d",
   "metadata": {},
   "source": [
    "# IX. Concluciones:\n",
    "* En este Notebook ha aprendido cual es el proceso durante el entrenamiento de una red Neuronal.\n",
    "* Si bien es cierto uso la libreria __scikit-learn__, esta no es la unica alternativa disponible. De hecho existen diversas herramientas (librerias) con las que se puede trabajar. No obstante le recordamos siempre considerar aquellas de __codigo abierto__ (cuando la situacion lo requiera), ya que muchos modelos complejos se entrenan usando __software libre__.\n",
    "* Entrenar redes es una tarea ardua que involucra muchos factores, como la arquitectura de la red. De hecho diferentes arquitecturas resultan en performances variadas.\n",
    "* Es importante recordar que los datos de entrenamiento se usan para la red. Los datos de test se usan para evaluar. Es importante que no mezcle los datos, ya que obtendra resultados __sobre estimados__.\n",
    "* Existen diversas formas de division de datos. En este ejemplo hemos usado un 90-10%, donde 90% para entrenamiento y 10% para test. No obstante alternativas como la validacion cruzada y otras tambien se pueden aplicar.\n",
    "\n",
    "\n",
    "### 7. Pregunta: Despues de haber completado el Notebook, elabore un resumen resaltando los puntos mas importantes que ha encontrado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2730ce",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
